{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-MpKxz14SSU"
      },
      "source": [
        "# Decision trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWa4yz4qbxkF"
      },
      "source": [
        "![img](https://pbs.twimg.com/media/B13n2VVCIAA0hJS.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EBDdjJ-ay0M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zguy6o5Pb3-x"
      },
      "source": [
        "Let's generate a toy dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdtf3-9WauYy"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "X_toy, y_toy = make_blobs(n_samples=400,\n",
        "                          centers=[[0., 1.], [1., 2.]],\n",
        "                          random_state=14)\n",
        "\n",
        "plt.scatter(X_toy[~(y_toy==1), 0], X_toy[~(y_toy==1), 1], alpha=0.8, marker='s', label='0', c='deepskyblue')\n",
        "plt.scatter(X_toy[y_toy==1,    0], X_toy[y_toy==1,    1], alpha=0.8, marker='^', label='1', c='orange')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9V31PoNcFuO"
      },
      "source": [
        "## Decision trees out of the box"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBmN8Ildbe0d"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr-JTRwCcDR1"
      },
      "source": [
        "DecisionTreeClassifier has a number of parameters:\n",
        "* `max_depth` – a limit on tree depth (default – no limit)\n",
        "* `min_samples_split` – there should be at least this many samples to split further (default – 2)\n",
        "* `min_samples_leaf` – there should be at least this many samples on one side of a split to consider it valid (default – 1).\n",
        "* `criterion` – 'gini' or 'entropy' – split stuff over this parameter (default : gini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX2Dm7onbq2s"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_toy, y_toy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM02fOjxcMic"
      },
      "source": [
        "### Plot decision surface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0jDlaAXA1Ee"
      },
      "source": [
        "You may also check [sklearn.inspection.DecisionBoundaryDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.DecisionBoundaryDisplay.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ODNVnC-jB9"
      },
      "source": [
        "Let's plot the tree we've fitted above:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plot_decision_regions(X_toy, y_toy, clf);"
      ],
      "metadata": {
        "id": "3mJJ-iAQtZ3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RWucAGNcY-t"
      },
      "source": [
        "### Tree depth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImiOildL-jCE"
      },
      "source": [
        "First we are going to split our data to train and test subsets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6clG_qq-jCE"
      },
      "outputs": [],
      "source": [
        "X_toy_train, X_toy_test, y_toy_train, y_toy_test = \\\n",
        "    train_test_split(X_toy, y_toy, test_size=0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeL0PME0-jCI"
      },
      "source": [
        "Let's investigate how the decision boundary depends on the tree depth. Maximum tree depth is defined by the `max_depth` parameter: depict   decision boundary plots for both train and test datasets (separately).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppdUZd6U-jCI"
      },
      "outputs": [],
      "source": [
        "depth_values = [1, 2, 3, 5, 10, None]\n",
        "\n",
        "fig, axs = plt.subplots(ncols = 2, nrows = len(depth_values), figsize=(20, 30))\n",
        "\n",
        "\n",
        "for i in range(len(depth_values)):\n",
        "  max_depth = depth_values[i]\n",
        "\n",
        "  dt = DecisionTreeClassifier(max_depth=max_depth, random_state=13)\n",
        "  dt.fit(X_toy_train, y_toy_train)\n",
        "\n",
        "\n",
        "  axs[i][0].set_title(\n",
        "            \"max_depth = {} Train accuracy = {} \".format(max_depth, accuracy_score(y_toy_train, dt.predict(X_toy_train)))\n",
        "        )\n",
        "  axs[i][0].axis(\"off\")\n",
        "  axs[i][1].set_title(\n",
        "            \"max_depth = {} Test  accuracy = {} \".format(max_depth, accuracy_score(y_toy_test, dt.predict(X_toy_test)))\n",
        "        )\n",
        "  axs[i][1].axis(\"off\")\n",
        "  plot_decision_regions(X_toy_train, y_toy_train, dt, ax=axs[i][0])\n",
        "  plot_decision_regions(X_toy_test,  y_toy_test,  dt, ax=axs[i][1])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overfitting"
      ],
      "metadata": {
        "id": "TclXHg4izIjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trees seem to overfit. Let's conduct an experiment: choose random 90\\% of the sample and fit the tree. And check if they differ."
      ],
      "metadata": {
        "id": "Je-w_jGmzKT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15, 12))\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        seed_idx = 3 * i + j\n",
        "        np.random.seed(seed_idx)\n",
        "        dt = DecisionTreeClassifier(random_state=13)\n",
        "        idx_part = np.random.choice(len(X_toy_train), replace=False, size=int(0.9 * len(X_toy_train)))\n",
        "        X_part, y_part = X_toy_train[idx_part, :], y_toy_train[idx_part]\n",
        "        dt.fit(X_part, y_part)\n",
        "        ax[i][j].set_title(\"sample #{}\".format(seed_idx))\n",
        "        ax[i][j].axis(\"off\")\n",
        "        plot_decision_regions(X_part, y_part, dt, ax=ax[i][j])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "efBErNQSzWBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lgCWhbEc77C"
      },
      "source": [
        "### Toy multiclass data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48yemIKk-jCQ"
      },
      "source": [
        "Now let's try out a multiclass classification case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wahVk0jegnb_"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/Majid-Sohrabi/MLDM-2025/main/07-trees/data.npz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7iUjzyo-jCU"
      },
      "source": [
        "Firstly, we'll load the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2qKojahYhm1"
      },
      "outputs": [],
      "source": [
        "data = np.load('data.npz')\n",
        "X, y = data[\"X\"], data[\"y\"]\n",
        "\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cuuN5L6-jCb"
      },
      "source": [
        "And then split it to train and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybPi8TNtYlgV"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X, y, test_size=0.5, random_state=1337)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5l3oJDs-jCi"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 7))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='rainbow', s = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6NA1BGH-jCo"
      },
      "source": [
        "Now that we've had a look at the data, let's fit a decision tree on it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dvkVwtLZjDA"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train accuracy = ', accuracy_score(y_train, clf.predict(X_train)))\n",
        "print('Test  accuracy = ', accuracy_score(y_test, clf.predict(X_test)))"
      ],
      "metadata": {
        "id": "uNeHRAqkw8F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3s03yi0-jCs"
      },
      "source": [
        "and plot the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEHFL51JY02v"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 16))\n",
        "plt.subplot(2, 1, 1)\n",
        "plot_decision_regions(X_train, y_train, clf)\n",
        "plt.subplot(2, 1, 2)\n",
        "plot_decision_regions(X_test, y_test, clf);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmEoJSDxdHHs"
      },
      "source": [
        "#### We need a better tree!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwZ4BVxobkiu"
      },
      "source": [
        "Try adjusting the parameters of DecisionTreeClassifier to improve the test accuracy.\n",
        " * Accuracy >= 0.72 - not bad for a start\n",
        " * Accuracy >= 0.75 - better, but not enough\n",
        " * Accuracy >= 0.77 - pretty good\n",
        " * Accuracy >= 0.78 - great! (probably the best result for a single tree) **(1 point)**\n",
        "\n",
        "Feel free to modify the DecisionTreeClassifier above instead of re-writing everything.\n",
        "\n",
        "**Note:** some of the parameters you can tune are under the \"Decision trees out of the box\" header."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvm8lSZx-K5C"
      },
      "source": [
        "## Feature transformations\n",
        "Try adding feature transformations using a pipeline and a transformation, e.g. function transformer.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "clf = make_pipeline(\n",
        "    FunctionTransformer(lambda X: np.concatenate([X, X**2], axis=1)),\n",
        "    DecisionTreeClassifier()\n",
        ")\n",
        "```\n",
        "\n",
        "Which transformations should improve the score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCc2zNmcVOCz"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "clf = make_pipeline(\n",
        "FunctionTransformer(lambda X: X),\n",
        "DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print('Train accuracy = ', accuracy_score(y_train, clf.predict(X_train)))\n",
        "print('Test  accuracy = ', accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 16))\n",
        "plt.subplot(2, 1, 1)\n",
        "plot_decision_regions(X_train, y_train, clf)\n",
        "plt.subplot(2, 1, 2)\n",
        "plot_decision_regions(X_test, y_test, clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0sTlV_msz3H"
      },
      "source": [
        "```\n",
        "```\n",
        "```\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvifS1edLmnd"
      },
      "source": [
        "We've talked a lot about the importance of feature scaling. Why aren't we doing it here?\n",
        "\n",
        "Let's try adding a standard scaler to the pipeline of our model and check how it affects the result. Can you explain the result?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtF5Nsc_9uW0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX25hYFvL8DP"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier(max_depth = 3, min_samples_split=6)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print('No scaling')\n",
        "print('Train accuracy = ', accuracy_score(y_train, clf.predict(X_train)))\n",
        "print('Test  accuracy = ', accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train_scaled = sc.fit_transform(X_train)\n",
        "X_test_scaled = sc.transform(X_test)\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "print('With scaling')\n",
        "print('Train accuracy = ', accuracy_score(y_train, clf.predict(X_train_scaled)))\n",
        "print('Test  accuracy = ', accuracy_score(y_test, clf.predict(X_test_scaled)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a tree"
      ],
      "metadata": {
        "id": "ZnqZ1wttzkFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plt.figure(figsize=(15, 8), dpi=100)\n",
        "plot_tree(clf, fontsize=10, filled=True);"
      ],
      "metadata": {
        "id": "5H2AHSP_zola"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciMVTsfrCzEz"
      },
      "source": [
        "## Tree pruning (Minimal Cost-Complexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlV80NDkC2n9"
      },
      "source": [
        "Let tree $T$ have the total weighted sample impurity of the terminal nodes $R(T)$.\n",
        "\n",
        "Can prune the tree by minimizing:\n",
        "$$R_\\alpha(T) = R(T) + \\alpha\\left|T\\right|,$$\n",
        "where $\\alpha\\geq0$, and $\\left|T\\right|$ is the number of terminal nodes in the tree.\n",
        "\n",
        "Let $T_t$ be the subtree tree whose root node is $t\\in T$.\n",
        "\n",
        "$T_t$ will be pruned out (i.e. replaced with $t$ as the terminal node) if:\n",
        "$$R(t)+\\alpha < R(T_t)+\\alpha\\left|T_t\\right|$$\n",
        "or in other words if:\n",
        "$$\\alpha > \\alpha_{eff}(t)=\\frac{R(t) - R(T_t)}{\\left|T_t\\right|-1}$$\n",
        "\n",
        "One can use the `cost_complexity_pruning_path` method of `DecisionTreeClassifier` to get the list of $\\alpha_{eff}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg80TYO9FXVn"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "\n",
        "plt.plot(ccp_alphas, impurities, marker='o', drawstyle=\"steps-post\")\n",
        "plt.xlabel(\"effective alpha\")\n",
        "plt.ylabel(\"total impurity of leaves\")\n",
        "plt.title(\"Total Impurity vs effective alpha for training set\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UONd5irJBnV"
      },
      "source": [
        " `DecisionTreeClassifier` has a `ccp_alpha` parameter to prune the tree.\n",
        "\n",
        " For each of the `ccp_alphas` defined above fit a tree, and then make 3 plots:\n",
        " - tree depth vs alpha\n",
        " - number of nodes in the tree vs alpha\n",
        " - train and test accuracies vs alpha\n",
        "\n",
        "Attribute  `clf.tree_.max_depth` gives the tree depth , and `clf.tree_.node_count` - number of nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD2XuoXpGoJd"
      },
      "outputs": [],
      "source": [
        "tree_depth = []\n",
        "number_of_nodes = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "for alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(ccp_alpha = alpha).fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = clf.predict(X_train)\n",
        "    y_test_pred = clf.predict(X_test)\n",
        "\n",
        "    train_acc.append(accuracy_score(y_train, y_train_pred))\n",
        "    test_acc.append(accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "    number_of_nodes.append(clf.tree_.node_count)\n",
        "    tree_depth.append(clf.tree_.max_depth)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5*3, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(ccp_alphas, train_acc, label='Train accuracy')\n",
        "plt.plot(ccp_alphas, test_acc,  label='Test accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel(r'$\\alpha$')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(ccp_alphas, number_of_nodes)\n",
        "plt.title('Number of nodes')\n",
        "plt.xlabel(r'$\\alpha$')\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(ccp_alphas, tree_depth)\n",
        "plt.title('Tree depth')\n",
        "plt.xlabel(r'$\\alpha$')\n",
        "plt.grid()\n"
      ],
      "metadata": {
        "id": "DFZaweQb2EO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ccp_alphas[np.argmax(test_acc)]"
      ],
      "metadata": {
        "id": "GVP0hERKVEIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision trees vs linear models"
      ],
      "metadata": {
        "id": "_tqvVP1e1mHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data is easy for linear models, but hard for trees."
      ],
      "metadata": {
        "id": "CJLHG1h91v2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(13)\n",
        "n = 500\n",
        "X = np.zeros(shape=(n, 2))\n",
        "X[:, 0] = np.linspace(-5, 5, 500)\n",
        "X[:, 1] = X[:, 0] + 0.5 * np.random.normal(size=n)\n",
        "y = (X[:, 1] > X[:, 0]).astype(int)\n",
        "plt.scatter(X[:, 0], X[:, 1], s=10, c=y);"
      ],
      "metadata": {
        "id": "CKYZSP6a1odc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=13\n",
        ")\n",
        "\n",
        "lr = LogisticRegression(random_state=13)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "print(f\"Linear model accuracy: {accuracy_score(y_pred_lr, y_test):.2f}\")\n",
        "\n",
        "plot_decision_regions(X_test, y_test, lr);"
      ],
      "metadata": {
        "id": "MIFU4VGR1lrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=13)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "print(f\"Decision tree accuracy: {accuracy_score(y_pred_dt, y_test):.2f}\")\n",
        "\n",
        "plot_decision_regions(X_test, y_test, dt);"
      ],
      "metadata": {
        "id": "HxarcuLO1pzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision tree for regression"
      ],
      "metadata": {
        "id": "3lW1yCKS0CNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import  mean_squared_error\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "california = fetch_california_housing()\n",
        "california_X = pd.DataFrame(data=california.data, columns=california.feature_names)\n",
        "california_Y = california.target\n",
        "print(f\"X shape: {california_X.shape}, Y shape: {california_Y.shape}\")\n",
        "california_X.head()"
      ],
      "metadata": {
        "id": "muGQbWNH0LC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    california_X, california_Y, test_size=0.25, random_state=13\n",
        ")\n",
        "\n",
        "dt = DecisionTreeRegressor(max_depth=3, random_state=13)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "print(mean_squared_error(y_test, dt.predict(X_test)))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plot_tree(dt, feature_names=california_X.columns, filled=True, rounded=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g2TbNHsL0O_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth_array = range(2, 20)\n",
        "mse_array = []\n",
        "\n",
        "for max_depth in max_depth_array:\n",
        "    dt = DecisionTreeRegressor(max_depth=max_depth, random_state=13)\n",
        "    dt.fit(X_train, y_train)\n",
        "    mse_array.append(mean_squared_error(y_test, dt.predict(X_test)))\n",
        "\n",
        "plt.plot(max_depth_array, mse_array)\n",
        "plt.title(\"Dependence of MSE on max depth\")\n",
        "plt.xlabel(\"max depth\")\n",
        "plt.ylabel(\"MSE\");"
      ],
      "metadata": {
        "id": "Y-2sTT5h0f9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth_array[np.argmin(mse_array)]"
      ],
      "metadata": {
        "id": "pb5w_1ec0z3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's search for best hyperparameters using grid search:"
      ],
      "metadata": {
        "id": "O0m-gKJUVZtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "gs = GridSearchCV(DecisionTreeRegressor(random_state=13),\n",
        "                  param_grid={\n",
        "                      'max_features': ['auto', 'log2', 'sqrt'],\n",
        "                      'max_depth': list(range(2, 20)) + [None],\n",
        "                      'min_samples_leaf': list(range(20, 70, 3)) + [None]\n",
        "                  },\n",
        "                  cv=5,\n",
        "                  scoring='neg_mean_squared_error',\n",
        "                  verbose=5)\n",
        "gs.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "pNmjNpudVjQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs.best_params_"
      ],
      "metadata": {
        "id": "5cwljorcVvR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_squared_error(y_test, gs.predict(X_test)))"
      ],
      "metadata": {
        "id": "Ug9N3tX7Vy-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature importance"
      ],
      "metadata": {
        "id": "lLNh8YOVV-78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeRegressor(random_state=13, **gs.best_params_)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "df_importances = pd.DataFrame(\n",
        "    {\"feature\": california_X.columns, \"importance\": dt.feature_importances_}\n",
        ").sort_values(by=\"importance\", ascending=False).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "uk-tDwNI0yu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(df_importances['feature'], df_importances['importance'])\n",
        "plt.xticks(rotation=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "57abS8YVWUkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear dependency of features may influence the results:"
      ],
      "metadata": {
        "id": "fd9iuMx_Zxn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_feature1 = np.array((X_train.iloc[:, 0] * 2 + 3)).reshape(-1, 1)\n",
        "new_feature2 = np.array((X_train.iloc[:, 0] * 3 - 2)).reshape(-1, 1)\n",
        "X_train_new = np.hstack((X_train, new_feature1, new_feature2))\n",
        "\n",
        "dt.fit(X_train_new, y_train)\n",
        "\n",
        "df_importances = pd.DataFrame(\n",
        "    {\"feature\": np.concatenate([california_X.columns, ['MedInc1', 'MedInc2']]), \"importance\": dt.feature_importances_}\n",
        ").sort_values(by=\"importance\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "plt.bar(df_importances['feature'], df_importances['importance'])\n",
        "plt.xticks(rotation=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tgBRiTFZWioG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}